---
title: "2_batches_correlation_analysis"
author: "Johanna Mehler"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true               # Enable Table of Contents
    toc_float:              # Make the TOC floating
      collapsed: false      # Do not collapse TOC by default
      smooth_scroll: true   # Smooth scrolling to sections
    number_sections: true   # Numbered sections
    theme: readable         # Use a predefined theme for styling (optional)
    highlight: tango        # Syntax highlighting style (optional)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Libraries

```{r, include=FALSE}
library(tidyverse)
library(descr) 
library(ggplot2)
library(descr)
library(tidyverse)
library(corrplot)
library(corrr)


theme_set(theme_minimal())
```

## Read in Data

```{r}
# read in batches
batches <- read_csv("/Users/Jo/OneDrive/1_Hertie Studies/Thesis/Hertie-Thesis-Mehler/data/batches_2.csv")
```

# Pre-Processing

Create numeric Values (TRUE = 1, FALSE = 0) for all columns and remove the country column for now. Create dataframes for each category content, target etc.

```{r}
# Replace 'Answer.' with '' for all column names starting with 'Answer.'
names(batches) <- sub("^Answer\\.", "", names(batches))

# Convert boolean (logical) columns to numeric
data_numeric <- batches %>% 
  select(-ends_with("open"), -flag_comments, -Input.country, -Input.hate_definition, -Input.ResponseId) %>% 
  mutate(across(.cols = everything(), .fns = ~ as.numeric(. == TRUE)))

# take out answers that are flagged for revision
data_numeric_filtered <- data_numeric %>% filter(flag.flag == FALSE) %>% select(-flag.flag)

# create subsets for each category
data_content <- data_numeric %>% select(starts_with("content")) # 15
names(data_content) <- sub("^content\\.", "", names(data_content))

data_other_features <- data_numeric %>% select(starts_with("other")) # 7
names(data_other_features) <- sub("^other\\.", "", names(data_other_features))

data_scope <- data_numeric %>% select(starts_with("scope")) # 2
names(data_scope) <- sub("^scope\\.", "", names(data_scope))

data_sender <- data_numeric %>% select(starts_with("sender")) # 5
names(data_sender) <- sub("^sender\\.", "", names(data_sender))

data_target <- data_numeric %>% select(starts_with("target")) # 18
names(data_target) <- sub("^target\\.", "", names(data_target))
```

# Explore Correlations

## Variability of Items

Check for columns with no variability (problem for calculating correlation)

```{r}
# Function to check and report columns with only zeros
report_columns_with_only_zeros <- function(data) {
  # Identify columns with only zeros
  zero_var_cols <- apply(data, 2, function(column) all(column == 0))
  
  # Names of columns with only zeros
  columns_with_zeros <- names(data)[zero_var_cols]
  
  if(length(columns_with_zeros) > 0) {
    cat("Columns with only zeros:", paste(columns_with_zeros, collapse = ", "), "\n")
  } else {
    cat("No columns with only zeros found.\n")
  }
}

# Using the function with the data_numeric dataset
report_columns_with_only_zeros(data_numeric_filtered)
```

Because sender.power and sender.general is not used as classification item by the annotators, we will remove it from the dataset:

```{r}
data_numeric_filtered <- data_numeric_filtered %>% select(-sender.power, -general)
data_sender <- data_sender %>% select(-power, -general)
```


## Identifying Common Combinations

### Item Pairs

```{r}
# Add a unique row identifier to the dataset in order to group in long format later
data_numeric_filtered_ID <- data_numeric_filtered %>%
  mutate(id = row_number())

# Convert data frame to long format, excluding the 'id' column from the pivot
data_long <- pivot_longer(data_numeric_filtered_ID, 
                          cols = -id, 
                          names_to = "variable", 
                          values_to = "value")

# Filter for TRUE values only
data_true <- filter(data_long, value == TRUE)

# Adjusted code to skip groups with fewer than 2 items
data_pairs <- data_true %>%
  group_by(id) %>%
  filter(n() >= 2) %>% # Ensure group has at least 2 items
  summarise(pairs = list(combn(variable, 2, simplify = FALSE))) %>%
  unnest(pairs) %>%
  ungroup() %>%
  mutate(pairs = map_chr(pairs, ~paste(sort(.x), collapse = " & "))) %>%
  count(pairs, sort = TRUE)

# Display the most common pairs
data_pairs %>% head(8)
```


### Item Triples

```{r}
# Adjusted code to create triples
data_triples <- data_true %>%
  group_by(id) %>%
  filter(n() >= 3) %>% # Ensure group has at least 2 items
  summarise(triples = list(combn(variable, 3, simplify = FALSE))) %>%
  unnest(triples) %>%
  ungroup() %>%
  mutate(triples = map_chr(triples, ~paste(sort(.x), collapse = " & "))) %>%
  count(triples, sort = TRUE)

# Display the most common pairs
data_triples %>% head(8)
```


# Correlation Matrix

## Overview

```{r}
# Assuming `data` is your dataframe containing only boolean variables
cor_matrix <- cor(data_numeric_filtered, method = "pearson")

cor_matrix %>% corrplot(method = "color", type = "lower", tl.cex = 0.5, tl.col = "black")
```

## Correlation per component

### Content

```{r}
# content
names(data_content) <- sub("^content\\.", "", names(data_content))
data_content %>% cor(method = "pearson") %>% corrplot(method = "color", type = "lower", tl.col = "black")
```

### Target

```{r}
# target
names(data_target) <- sub("^target\\.", "", names(data_target))
data_target %>% cor(method = "pearson") %>% corrplot(method = "shade", type = "lower", tl.col = "black")
```

### Sender

```{r}
# sender
names(data_sender) <- sub("^sender\\.", "", names(data_sender))
data_sender %>% cor(method = "pearson") %>% corrplot(method = "shade", type = "lower", tl.col = "black")
```

### Other Features

```{r}
# other features
names(data_other_features) <- sub("^other\\.", "", names(data_other_features))
data_other_features %>% cor(method = "pearson") %>% corrplot(method = "shade", type = "lower", tl.col = "black")
```


## Correlation network graph

### Preparation

```{r}
# libraries
library(tidygraph)
library(ggraph)


# select only boolean variables of all classification scheme items
#batch_items <- batches %>% select(-ends_with("open"), -Answer.flag_comments, -Input.country, -Input.hate_definition)

# Assuming `data` is your dataframe containing only boolean variables
cor_matrix <- cor(data_numeric_filtered, method = "pearson")

# Assuming 'data' is your dataframe and 'cor_matrix' is computed from it
var_names <- rownames(cor_matrix) # Assuming rownames are your variable names

# Convert the correlation matrix to a long format, including variable names
cor_data <- as.data.frame(as.table(cor_matrix)) %>%
  filter(Var1 != Var2) %>% # Exclude self-correlations
  mutate(Var1 = factor(Var1, levels = var_names),
         Var2 = factor(Var2, levels = var_names)) %>%
  filter(abs(Freq) > 0.2) # Filter to simplify the network, adjust threshold as needed

# Assuming cor_data is prepared correctly before this step
# Ensure cor_data has a 'name' column for nodes or adjust accordingly
```

### Create Network data

```{r}
# Prepare nodes and edges data frames
nodes <- data.frame(name = unique(c(as.character(cor_data$Var1), as.character(cor_data$Var2))))
edges <- cor_data

# prepare node size
counts <- cor_data %>% count(Var1, Var2, sort = TRUE)

# Use nodes and edges to create the graph
graph <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE)
```


### Plot Network

red = "negative correlation"

blue = "positive correlation"

Filter to simplify the network: show only correlations > 0.2 (done in preparation step above)

```{r}
# Now, when you activate nodes, they already have a 'name' attribute
ggraph(graph, layout = 'fr') +
  geom_edge_link(aes(edge_width = abs(Freq), edge_color = Freq > 0), show.legend = FALSE) +
  geom_node_point(size = 3, color = "skyblue") +
  geom_node_text(aes(label = name), repel = TRUE, size = 3) + # Now 'name' is available
  scale_edge_color_manual(values = c("red" = "negative correlation", "blue" = "positive correlation")) +
  ggtitle("Network Visualization of Boolean Variables Correlation") +
  theme_void()
```




