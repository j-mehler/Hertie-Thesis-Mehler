---
title: "Regressions"
author: "Johanna Mehler"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true               # Enable Table of Contents
    toc_float:              # Make the TOC floating
      collapsed: false      # Do not collapse TOC by default
      smooth_scroll: true   # Smooth scrolling to sections
    number_sections: true   # Numbered sections
    theme: readable         # Use a predefined theme for styling (optional)
    highlight: tango        # Syntax highlighting style (optional)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data preparation

## Libraries and read in data

```{r}
library(tidyverse)
library(here)
library(table1)
library(ggplot2)
library(lmtest)

data <- read_csv(here("data", "data_combined.csv"), 
                 col_types = cols(
                   academic_status = col_factor(levels = c("academic", "non-academic")), 
                   educ_cat = col_factor(levels = c("Low", "Intermediate", "High")), 
                   gender = col_factor(levels = c("Male", "Female")), 
                   age_cat = col_factor(levels = c("18-29", "30-49", "50-69", "70+")),
                   polinterest = col_factor(levels = c("1", "2", "3", "4")), 
                   polinterest_cat_3 = col_factor(levels = c("Low", "Intermediate", "High")),
                   minority = col_factor(levels = c("0", "1")), 
                   minority_cat = col_factor(levels = c("Non-minority", "Minority")),
                   empathy_pc_cat = col_factor(levels = c("Less empathetic", "More empathetic")),
                   exp_hate_speech_cat = col_factor(levels = c("Less experience", "More experience")), 
                   exp_hostile_engagement_cat = col_factor(levels = c("Less experience", "More experience")), 
                   cluster = col_factor(levels = c("A", "B", "C", "D"))
                 ))

# filter out NA's in academic status and extreme outliers
data <- data %>% filter(!is.na(educ_cat), !is.na(academic_status), text_length < 1000, readability_score < 40)

# check data types and scales
data %>% summary()

# print table
table1(~ academic_status + educ_cat + gender + age_cat + polinterest + minority_cat + empathy_pc_cat + exp_hate_speech_cat + exp_hostile_engagement_cat + cluster, data = data)



```

### Compare with whole dataset (19,000+)

```{r}
# compare with whole dataset
data_all <- read_csv(here("data/data_clean.csv"))

# print table
table1(~ educ_cat + gender + age_cat + polinterest + minority_cat, data = data_all)

```

# Regressions

## Text Length

### More controls

```{r}
# Linear regression model with all controls
model_text_length <- lm(text_length_log2 ~ academic_status + gender + age_cat + minority_cat + polinterest_cat_3 + empathy_pc + exp_hate_speech + exp_hostile_engagement, data = data)

summary(model_text_length)
```

***Residuals Plot for Homoscedasticity and Linearity***

check if the residuals (differences between observed and predicted values) display constant variance across all levels of the predicted values (homoscedasticity) and if the relationship between the predictors and the outcome is linear.

**Homoscedasticity**: The spread of residuals should be roughly constant across all fitted values.

**Linearity**: The residuals should be randomly dispersed around the horizontal axis, without any systematic shape.

```{r}
# Plotting residuals vs. fitted values
plot(model_text_length, which = 1)
```



***Q-Q Plots for Normality of Residuals***

Q-Q (quantile-quantile) plot to assess whether the residuals follow a normal distribution

```{r}
# Q-Q plot
qqnorm(residuals(model_text_length))
qqline(residuals(model_text_length))
```

***Variance Inflation Factor (VIF) for Multicollinearity***

Assesses how much the variance of a coefficient is inflated due to multicollinearity in the model. VIF values above 5 or 10 indicate high multicollinearity that could be problematic.

```{r}
library(car)

vif(model_text_length)
```


### Less Controls

```{r}
# Linear regression model with less controls (assuming that they are later in the causal chain)
model_text_length <- lm(text_length ~ academic_status + gender + age_cat + minority_cat + exp_hate_speech, data = data)

summary(model_text_length)
```


***Residuals Plot for Homoscedasticity and Linearity***

check if the residuals (differences between observed and predicted values) display constant variance across all levels of the predicted values (homoscedasticity) and if the relationship between the predictors and the outcome is linear.

**Homoscedasticity**: The spread of residuals should be roughly constant across all fitted values.

**Linearity**: The residuals should be randomly dispersed around the horizontal axis, without any systematic shape.

```{r}
# Plotting residuals vs. fitted values
plot(model_text_length, which = 1)
```



***Q-Q Plots for Normality of Residuals***

Q-Q (quantile-quantile) plot to assess whether the residuals follow a normal distribution

```{r}
# Q-Q plot
qqnorm(residuals(model_text_length))
qqline(residuals(model_text_length))
```

***Variance Inflation Factor (VIF) for Multicollinearity***

Assesses how much the variance of a coefficient is inflated due to multicollinearity in the model. VIF values above 5 or 10 indicate high multicollinearity that could be problematic.

```{r}
library(car)

vif(model_text_length)
```

## Readability

### More controls

```{r}
# Linear regression model with all controls
model_readability <- lm(readability_score ~ academic_status + gender + age_cat + minority_cat + polinterest_cat_3 + empathy_pc + exp_hate_speech + exp_hostile_engagement, data = data)

summary(model_readability)
```



***Residuals Plot for Homoscedasticity and Linearity***

check if the residuals (differences between observed and predicted values) display constant variance across all levels of the predicted values (homoscedasticity) and if the relationship between the predictors and the outcome is linear.

**Homoscedasticity**: The spread of residuals should be roughly constant across all fitted values.

**Linearity**: The residuals should be randomly dispersed around the horizontal axis, without any systematic shape.

```{r}
# Plotting residuals vs. fitted values
plot(model_readability, which = 1)
```



***Q-Q Plots for Normality of Residuals***

Q-Q (quantile-quantile) plot to assess whether the residuals follow a normal distribution

```{r}
# Q-Q plot
qqnorm(residuals(model_readability))
qqline(residuals(model_readability))
```

***Variance Inflation Factor (VIF) for Multicollinearity***

Assesses how much the variance of a coefficient is inflated due to multicollinearity in the model. VIF values above 5 or 10 indicate high multicollinearity that could be problematic.

```{r}
library(car)

vif(model_readability)
```

### Less Controls

```{r}
# Linear regression model with less controls (assuming that they are later in the causal chain)
model_readability <- lm(readability_score ~ academic_status + gender + age_cat + minority_cat + exp_hate_speech, data = data)

summary(model_readability)
```



***Residuals Plot for Homoscedasticity and Linearity***

check if the residuals (differences between observed and predicted values) display constant variance across all levels of the predicted values (homoscedasticity) and if the relationship between the predictors and the outcome is linear.

**Homoscedasticity**: The spread of residuals should be roughly constant across all fitted values.

**Linearity**: The residuals should be randomly dispersed around the horizontal axis, without any systematic shape.

```{r}
# Plotting residuals vs. fitted values
plot(model_text_length, which = 1)
```



***Q-Q Plots for Normality of Residuals***

Q-Q (quantile-quantile) plot to assess whether the residuals follow a normal distribution

```{r}
# Q-Q plot
qqnorm(residuals(model_text_length))
qqline(residuals(model_text_length))
```

***Variance Inflation Factor (VIF) for Multicollinearity***

Assesses how much the variance of a coefficient is inflated due to multicollinearity in the model. VIF values above 5 or 10 indicate high multicollinearity that could be problematic.

```{r}
library(car)

vif(model_text_length)
```

## Predictability of Political Orientation

### More controls

```{r}
# Linear regression model with all controls
model_leftright_pred_score <- lm(leftright_pred_score ~ academic_status + gender + age_cat + minority_cat + polinterest_cat_3 + empathy_pc + exp_hate_speech + exp_hostile_engagement, data = data)

summary(model_leftright_pred_score)
```



***Residuals Plot for Homoscedasticity and Linearity***

check if the residuals (differences between observed and predicted values) display constant variance across all levels of the predicted values (homoscedasticity) and if the relationship between the predictors and the outcome is linear.

**Homoscedasticity**: The spread of residuals should be roughly constant across all fitted values.

**Linearity**: The residuals should be randomly dispersed around the horizontal axis, without any systematic shape.

```{r}
# Plotting residuals vs. fitted values
plot(model_text_length, which = 1)
```



***Q-Q Plots for Normality of Residuals***

Q-Q (quantile-quantile) plot to assess whether the residuals follow a normal distribution

```{r}
# Q-Q plot
qqnorm(residuals(model_text_length))
qqline(residuals(model_text_length))
```

***Variance Inflation Factor (VIF) for Multicollinearity***

Assesses how much the variance of a coefficient is inflated due to multicollinearity in the model. VIF values above 5 or 10 indicate high multicollinearity that could be problematic.

```{r}
library(car)

vif(model_text_length)
```


### Less Controls

```{r}
# Linear regression model with less controls (assuming that they are later in the causal chain)
model_leftright_pred_score <- lm(leftright_pred_score ~ academic_status + gender + age_cat + minority_cat + exp_hate_speech, data = data)

summary(model_leftright_pred_score)
```




***Residuals Plot for Homoscedasticity and Linearity***

check if the residuals (differences between observed and predicted values) display constant variance across all levels of the predicted values (homoscedasticity) and if the relationship between the predictors and the outcome is linear.

**Homoscedasticity**: The spread of residuals should be roughly constant across all fitted values.

**Linearity**: The residuals should be randomly dispersed around the horizontal axis, without any systematic shape.

```{r}
# Plotting residuals vs. fitted values
plot(model_leftright_pred_score, which = 1)
```



***Q-Q Plots for Normality of Residuals***

Q-Q (quantile-quantile) plot to assess whether the residuals follow a normal distribution

```{r}
# Q-Q plot
qqnorm(residuals(model_leftright_pred_score))
qqline(residuals(model_leftright_pred_score))
```

***Variance Inflation Factor (VIF) for Multicollinearity***

Assesses how much the variance of a coefficient is inflated due to multicollinearity in the model. VIF values above 5 or 10 indicate high multicollinearity that could be problematic.

```{r}
library(car)

vif(model_leftright_pred_score)
```

## Cluster (multinomial logistic regression)

###

```{r}
library(nnet)

# Fit multinomial logistic regression model
model_cluster <- multinom(cluster ~ academic_status + gender + age_cat + minority_cat + polinterest_cat_3 + empathy_pc + exp_hate_speech + exp_hostile_engagement, data = data)

summary(model_cluster)
```

### Less controls

```{r}
# Fit multinomial logistic regression model
model_cluster <- multinom(cluster ~ academic_status + gender + age_cat + minority_cat + exp_hate_speech, data = data)

summary(model_cluster)
```


These coefficients represent the log odds of being in each category of the outcome variable, compared to the reference category, for a one-unit increase in the predictor variable.

Convert coefficients (log-odds units) to odds ratios for easier interpretation:


```{r}
# convert coefficients (log-odds units) to odds ratios for easier interpretation
exp(coef(model_cluster))

```

An odds ratio greater than 1 indicates an increased likelihood of being in the category compared to the reference category, for a one-unit increase in the predictor variable.


### Validation

**McFadden's R-squared**

McFadden's R-squared is defined as 1 minus the ratio of the log-likelihood of the model over the log-likelihood of the null model (a model with no predictors except the intercept). It gives an indication of the improvement in fit that the model provides over the null model.


```{r}
# Calculate the log-likelihood of the model
logLik_model <- logLik(model_cluster)

# Fit a null model (with only the intercept)
null_model <- multinom(cluster ~ 1, data = data)

# Calculate the log-likelihood of the null model
logLik_null <- logLik(null_model)

# Calculate McFadden's R-squared
mcfadden_r_squared <- 1 - (as.numeric(logLik_model) / as.numeric(logLik_null))

# Print McFadden's R-squared
print(mcfadden_r_squared)

```

***Interpretation***

A value closer to 0 indicates that the model does not improve much upon the null model.
Values closer to 1 suggest that the model provides a significant improvement over the null model.
McFadden suggested that a value of 0.2 to 0.4 represents a good fit.


**Confusion Matrix and Classification Accuracy**

The confusion matrix compares the actual vs. predicted classifications and is a powerful tool for understanding model performance across different categories.

```{r}
library(caret)

# Filtering to complete cases, assuming 'df' is your dataset
data_complete <- data[complete.cases(data), ]

# Refit the model with the complete cases (if not already done)
model_cluster_complete <- multinom(cluster ~ academic_status + gender + age_cat + minority_cat + exp_hate_speech, data = data_complete)

# Generate new predictions
predicted_values_complete <- predict(model_cluster_complete, type="class")

# Now try the confusion matrix again
confusionMatrix(data = predicted_values_complete, reference = data_complete$cluster)
```

