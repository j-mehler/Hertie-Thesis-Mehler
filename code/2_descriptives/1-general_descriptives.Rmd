---
title: "General Descriptives"
author: "Johanna Mehler"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true               # Enable Table of Contents
    toc_float:              # Make the TOC floating
      collapsed: false      # Do not collapse TOC by default
      smooth_scroll: true   # Smooth scrolling to sections
    number_sections: true   # Numbered sections
    theme: readable         # Use a predefined theme for styling (optional)
    highlight: tango        # Syntax highlighting style (optional)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# General Descriptives

```{r}
library(tidyverse)
library(ggplot2)
library(here)
library(table1)
library(gtsummary)
library(stargazer)

# load reprocessed data
data <- read_csv(here("data", "data_combined.csv"), 
                 col_types = cols(
                   academic_status = col_factor(levels = c("non-academic", "academic")),
                   educ_cat = col_factor(levels = c("Low", "Intermediate", "High")), 
                   gender = col_factor(levels = c("Male", "Female", "Other")), 
                   monority_cat = col_factor(levels = c("Non-minority", "Minority")),
                   age_cat = col_factor(levels = c("18-29", "30-49", "50-69", "70+")),
                   polinterest_cat_3 = col_factor(levels = c("Low", "Intermediate", "High")),
                   empathy_pc_cat = col_factor(levels = c("Less empathetic", "More empathetic")),
                   exp_hate_speech_cat = col_factor(levels = c("Less experience", "More experience")), 
                   exp_hostile_engagement_cat = col_factor(levels = c("Less experience", "More experience")), 
                   cluster = col_factor(levels = c("Denying/Nonsense", "Content-based", "Harms-based", "Harms-based narrow")),
                   leftright_cat = col_factor(levels = c("liberal/left", "moderate/center", "conservative/right")),
                   commitment_cat = col_factor(levels = c("Below average", "Above average"))
                 ))

data <- data %>% drop_na(academic_status, gender, age_cat, polinterest_cat_3, leftright_cat, empathy_pc_cat, exp_hate_speech_cat, exp_hostile_engagement_cat, commitment_cat)
```

## Distribution of Variables of Interest (categorical)

```{r}
# Approach with table1 library

# take out missing values in academic_status
data_clean <- data %>% select(academic_status, country, gender, age_cat, polinterest_cat_3, leftright_cat, empathy_pc_cat, exp_hate_speech_cat, exp_hostile_engagement_cat, commitment_cat)

table1(~ country + gender + age_cat + polinterest_cat_3 + leftright_cat + empathy_pc_cat + exp_hate_speech_cat + exp_hostile_engagement_cat + commitment_cat | academic_status, data = data_clean)
```

```{r}
# approach with gtsummary
#data %>% 
#  select(country, Q_Language, academic_status, gender, age_cat, polinterest_cat_3, #empathy_pc_cat, exp_hate_speech_cat, exp_hostile_engagement_cat, commitment_cat) %>% 
#  tbl_summary()
```


## Distribution of Variables of Interest (numeric)

```{r}
# select variables of interest (numerical)
data_num <- data %>% select(age, polinterest, leftright, empathy_pc, exp_hate_speech, exp_hostile_engagement, commitment, commitment_log2,text_length, text_length_log2, readability_score, leftright_pred_error) 

stargazer(data_num, digits = 1)
```



# Missingness Sociodemographics

```{r}

# load reprocessed data
data_all <- read_csv(here("data/data_clean.csv"))
data_controls <- read_csv(here("data/all_controls.csv"))

# join data by ResponseId
data <- inner_join(data_all, data_controls, by = "ResponseId")

data <- data %>% select(
  open_hatedefinition,
  country,
  Q_Language,
  gender.x,
  age_cat.x,
  educ_cat,
  minority_cat.x,
  polinterest_cat_3,
  exp_hate_speech_cat,
  exp_hostile_engagement_cat,
  commitment_cat
)

```

### Missingness of Hate Speech Definition

```{r}
total <- data %>% count()

n <- data %>% filter(is.na(open_hatedefinition)) %>% count()

share <- n/total

share
```


Hate Definition (open_hatedefinition): 19.4 (24.1???) per cent missing. Seen that there is high missingness of nearly a quarter in my outcome variable, I want to find out more about people who did not specify their own definition of hate speech.


## Subset data in missing and not missing the hate speech definition

```{r}
# Filter rows where open_hatedefinition is missing
missing_hatedef <- data %>% 
  filter(is.na(open_hatedefinition)) 

not_missing_hatedef <- data %>% 
  filter(!is.na(open_hatedefinition)) 

# Create vector of variable names
variables <- data %>% select(-open_hatedefinition) %>% colnames()
```

## Calculate Percentages

```{r}
# Create vector of variable names
variables <- data %>% select(-open_hatedefinition) %>% colnames()

# Function to summarize data by missingness
summarize_data <- function(data, dataset_name) {
  data %>%
    pivot_longer(cols = all_of(variables), names_to = "variable", values_to = "value") %>%
    group_by(variable, value) %>%
    summarise(count = n(), .groups = "drop") %>%
    mutate(dataset = dataset_name)
}

# Filter rows where open_hatedefinition is missing and not missing
missing_hatedef <- data %>% filter(is.na(open_hatedefinition))
not_missing_hatedef <- data %>% filter(!is.na(open_hatedefinition))

# Apply the summarization function
missing_summary <- summarize_data(missing_hatedef, "Missing")
not_missing_summary <- summarize_data(not_missing_hatedef, "Not Missing")

# Combine summaries and calculate share
combined_summary <- rbind(missing_summary, not_missing_summary) %>%
  group_by(variable, value, dataset) %>%
  summarise(count = sum(count), .groups = "drop") %>%
  group_by(variable, value) %>%
  mutate(total = sum(count), share = count / total)

# View the combined summary
print(combined_summary)

```

## Plot Missingness with Confidence Intervals

```{r}
# Create vector of variable names
variables <- data %>% select(-open_hatedefinition) %>% colnames()

# Function to summarize data by missingness
summarize_data <- function(data, dataset_name) {
  data %>%
    pivot_longer(cols = all_of(variables), names_to = "variable", values_to = "value") %>%
    group_by(variable, value) %>%
    summarise(count = n(), .groups = "drop") %>%
    mutate(dataset = dataset_name)
}

# Filter rows where open_hatedefinition is missing and not missing
missing_hatedef <- data %>% filter(is.na(open_hatedefinition))
not_missing_hatedef <- data %>% filter(!is.na(open_hatedefinition))

# Apply the summarization function
missing_summary <- summarize_data(missing_hatedef, "Missing")
not_missing_summary <- summarize_data(not_missing_hatedef, "Not Missing")

# Combine summaries and calculate share and confidence intervals
combined_summary <- rbind(missing_summary, not_missing_summary) %>%
  group_by(variable, value, dataset) %>%
  summarise(count = sum(count), .groups = "drop") %>%
  group_by(variable, value) %>%
  mutate(total = sum(count), 
         share = count / total,
         se = sqrt(share * (1 - share) / total),  # Standard error of the proportion
         lower = share - 1.96 * se,              # Lower bound of 95% CI
         upper = share + 1.96 * se)              # Upper bound of 95% CI

combined_summary$variable <- factor(combined_summary$variable,
                                    levels = c("country", 
                                               "Q_Language",
                                               "gender.x",
                                               "age_cat.x",
                                               "minority_cat.x",
                                               "educ_cat", 
                                               "polinterest_cat_3",
                                               "exp_hate_speech_cat", 
                                               "exp_hostile_engagement_cat",
                                               "commitment_cat"))


# View the combined summary
print(combined_summary)

```


```{r, fig.width=8, fig.height=10}
combined_summary_missing <- combined_summary %>% filter(dataset == "Missing")

# Bar plot with error bars with customizable plot and legend titles
combined_summary_missing %>%
  ggplot(aes(x = value, y = share)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), fill = "skyblue", color = "white") +
  geom_errorbar(aes(ymin = lower, ymax = upper, group = dataset),
                width = 0.3,                    # Width of the horizontal lines at the ends of error bars
                position = position_dodge(0.75), # Match the position_dodge width with geom_bar
                color = "black",                 # Color of the error bars
                size = 0.5) +                   # Size of the error bars, making them narrow
  facet_wrap(~variable, scales = "free", ncol = 2,
             labeller = as_labeller(c("country" = "Country",
                         "Q_Language" = "Language",
                         "gender.x" = "Gender",
                         "age_cat.x" = "Age",
                         "minority_cat.x" = "Minority Status",
                         "educ_cat" = "Education", 
                         "polinterest_cat_3" = "Political Interest",
                         "exp_hate_speech_cat" = "Experience with Hate Speech", 
                         "exp_hostile_engagement_cat" = "Online hostile engagement",
                         "commitment_cat" = "Survey Commitment"
                         )
                                    )
             ) +
  labs(title = "Share of Missing Hate Speech Definitions by Subgroup", 
       x = "Subgroup", 
       y = "Share of Missingness") +
  scale_x_discrete(na.translate = FALSE) +
  scale_y_continuous(limits = c(0, 0.38), labels = scales::percent) + # Set uniform Y-axis limits
  coord_flip() +
  theme_bw() +
  theme(title = element_text(face = "bold"),
    strip.text = element_text(face = "bold")  # Make facet titles bold
  )

ggsave("missingness.png", path = here("figures"), width = 8, height = 10, dpi = 300)
```